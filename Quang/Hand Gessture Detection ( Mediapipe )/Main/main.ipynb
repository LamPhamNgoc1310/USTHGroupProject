{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import sys\n",
    "from collections import deque\n",
    "import itertools\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from keypoint_classifier import KeyPointClassifier\n",
    "from CvFpsCalc import CvFpsCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--device\", type=int, default=0)\n",
    "    parser.add_argument(\"--width\", help = 'cap width', type = int, default=960)\n",
    "    parser.add_argument(\"--height\", help=\"cap height\", type = int, default=540)\n",
    "    \n",
    "    parser.add_argument(\"--use_static_image_mode\", action='store_true')\n",
    "    parser.add_argument(\"--min_detection_confidence\",\n",
    "                        help='min_detection_confidence',\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "    parser.add_argument(\"--min_tracking_confidence\",\n",
    "                        help='min_tracking_confidence',\n",
    "                        type=int,\n",
    "                        default=0.5)\n",
    "\n",
    "    # Ignore unknown arguments (useful for Jupyter or IPython)\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # This will avoid the error when running in Jupyter\n",
    "        args = parser.parse_args([])  # Empty list, ignoring additional arguments\n",
    "    else:\n",
    "        # Standard argument parsing for command-line execution\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "\n",
    "    if 48 <= key <= 57:  # 0 ~ 9\n",
    "        number = key - 48\n",
    "    if key == 110:  # n\n",
    "        mode = 0\n",
    "    if key == 107:  # k\n",
    "        mode = 1\n",
    "    return number, mode\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Learn more about pre_process_landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Learn more about pre_process_point_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
    "                                        base_x) / image_width\n",
    "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
    "                                        base_y) / image_height\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_point_history = list(\n",
    "        itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Modify + Update data (csv file), and renew data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_csv(number, mode, landmark_list): \n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 9):\n",
    "        csv_path = 'keypoint.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *landmark_list])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, landmark_point):\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Little finger\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_info_text(image, brect, handedness, hand_sign_text): # ',finger_gesture_text'\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_info(image, fps, mode, number):\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (255, 255, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if 0 <= number <= 9:\n",
    "            cv.putText(image, \"NUM:\" + str(number), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Argument Parsing\"\"\"\n",
    "    args = get_args()\n",
    "\n",
    "    cap_device = args.device\n",
    "    cap_width = args.width\n",
    "    cap_height = args.height   \n",
    "\n",
    "    use_static_image_mode = args.use_static_image_mode\n",
    "    min_detection_confidence = args.min_detection_confidence\n",
    "    min_tracking_confidence = args.min_tracking_confidence  \n",
    "\n",
    "\n",
    "    use_brect = True\n",
    "\n",
    "\n",
    "    \"\"\"Camera preparation\"\"\"\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "\n",
    "    \"\"\"Model Loading\"\"\"\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    "\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "\n",
    "    \"\"\"Read Labels\"\"\"\n",
    "    with open('keypoint_classifier_label.csv',encoding='utf-8') as file:\n",
    "        keypoint_classifier_labels = csv.reader(file)\n",
    "        keypoint_classifier_labels = [row[0] for row in keypoint_classifier_labels] \n",
    "\n",
    "    \"\"\"Fps Measurement\"\"\"\n",
    "    cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
    "\n",
    "\n",
    "    \"\"\"Coordinate history \"\"\"\n",
    "    history_length = 16\n",
    "    point_history = deque(maxlen=history_length)\n",
    "\n",
    "    mode = 0\n",
    "\n",
    "    while True:\n",
    "        fps = cvFpsCalc.get()\n",
    "\n",
    "        \"\"\"Process Key (ESC: end)\"\"\"\n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        number, mode = select_mode(key, mode)  \n",
    "\n",
    "\n",
    "        \"\"\"Camera capture\"\"\"\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1) # Mirror display ()\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        \"\"\"Detection implementation\"\"\"\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True # drawing the landmarks or connections back onto the image once the detection has been completed\n",
    "\n",
    "        \"\"\"Visualization\"\"\"\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                \n",
    "                # Bounding Box calculation\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "\n",
    "                # Landmark calculation\n",
    "                Landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                # Conversion to relative coordinates / normalized coordinates\n",
    "                pre_processed_landmark_list = pre_process_landmark(Landmark_list)\n",
    "\n",
    "                # Write to the dataset file\n",
    "                logging_csv(number, mode, pre_processed_landmark_list) \n",
    "\n",
    "                # Hand sign classification\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "                if hand_sign_id == \"Not Applicable\":  # Point gesture\n",
    "                    point_history.append(Landmark_list[8])\n",
    "                else:\n",
    "                    point_history.append([0, 0])\n",
    "\n",
    "                # Drawing part\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, Landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    keypoint_classifier_labels[hand_sign_id],\n",
    "                    #point_history_classifier_labels[most_common_fg_id[0][0]],\n",
    "                )\n",
    "        else:\n",
    "            point_history.append([0, 0])\n",
    "\n",
    "        # debug_image = draw_point_history(debug_image, point_history)\n",
    "        debug_image = draw_info(debug_image, fps, mode, number)\n",
    "\n",
    "        # Display Rendered Image\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Argument Parsing\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Command-line arguments\n",
    "    parser.add_argument(\"--device\", type=int, default=0)\n",
    "    parser.add_argument(\"--width\", help=\"cap width\", type=int, default=960)\n",
    "    parser.add_argument(\"--height\", help=\"cap height\", type=int, default=540)\n",
    "    parser.add_argument(\"--use_static_image_mode\", action='store_true')\n",
    "    parser.add_argument(\"--min_detection_confidence\",\n",
    "                        help='min_detection_confidence',\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "    parser.add_argument(\"--min_tracking_confidence\",\n",
    "                        help='min_tracking_confidence',\n",
    "                        type=float,\n",
    "                        default=0.5)\n",
    "\n",
    "    # Ignore unknown arguments (useful for Jupyter or IPython)\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # This will avoid the error when running in Jupyter\n",
    "        args = parser.parse_args([])  # Empty list, ignoring additional arguments\n",
    "    else:\n",
    "        # Standard argument parsing for command-line execution\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Argument Parsing\"\"\"\n",
    "    args = get_args()\n",
    "\n",
    "    cap_device = args.device\n",
    "    cap_width = args.width\n",
    "    cap_height = args.height   \n",
    "\n",
    "    use_static_image_mode = args.use_static_image_mode\n",
    "    min_detection_confidence = args.min_detection_confidence\n",
    "    min_tracking_confidence = args.min_tracking_confidence  \n",
    "\n",
    "    \"\"\"Camera preparation\"\"\"\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "    \"\"\"Model Loading\"\"\"\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame horizontally for a later selfie-view display\n",
    "        frame = cv.flip(frame, 1)\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image to find hand landmarks\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # If hands are found, draw the landmarks\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the frame with landmarks\n",
    "        cv.imshow(\"Hand Landmarks\", frame)\n",
    "\n",
    "        # Break loop if 'q' is pressed\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close any OpenCV windows\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
