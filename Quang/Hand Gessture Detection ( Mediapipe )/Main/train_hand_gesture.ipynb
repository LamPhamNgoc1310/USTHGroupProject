{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Import File Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset/full.csv'\n",
    "model_save_path = 'keypoint_classifier.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Set number of classes and random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>wristX</th>\n",
       "      <th>wristY</th>\n",
       "      <th>wristZ</th>\n",
       "      <th>thumb_CmcX</th>\n",
       "      <th>thumb_CmcY</th>\n",
       "      <th>thumb_CmcZ</th>\n",
       "      <th>thumb_McpX</th>\n",
       "      <th>thumb_McpY</th>\n",
       "      <th>thumb_McpZ</th>\n",
       "      <th>...</th>\n",
       "      <th>pinky_McpZ</th>\n",
       "      <th>pinky_PipX</th>\n",
       "      <th>pinky_PipY</th>\n",
       "      <th>pinky_PipZ</th>\n",
       "      <th>pinky_DipX</th>\n",
       "      <th>pinky_DipY</th>\n",
       "      <th>pinky_DipZ</th>\n",
       "      <th>pinky_TipX</th>\n",
       "      <th>pinky_TipY</th>\n",
       "      <th>pinky_TipZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109.088745</td>\n",
       "      <td>314.879980</td>\n",
       "      <td>-5.032854e-07</td>\n",
       "      <td>151.700001</td>\n",
       "      <td>293.516436</td>\n",
       "      <td>-0.025845</td>\n",
       "      <td>184.029713</td>\n",
       "      <td>249.228258</td>\n",
       "      <td>-0.030217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>97.632666</td>\n",
       "      <td>209.177756</td>\n",
       "      <td>-0.016920</td>\n",
       "      <td>101.957064</td>\n",
       "      <td>235.674677</td>\n",
       "      <td>-0.003543</td>\n",
       "      <td>99.713421</td>\n",
       "      <td>245.986433</td>\n",
       "      <td>0.011983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>109.720602</td>\n",
       "      <td>314.435120</td>\n",
       "      <td>-5.082854e-07</td>\n",
       "      <td>152.480783</td>\n",
       "      <td>292.276154</td>\n",
       "      <td>-0.025500</td>\n",
       "      <td>183.990440</td>\n",
       "      <td>248.887711</td>\n",
       "      <td>-0.030684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>97.538586</td>\n",
       "      <td>209.035378</td>\n",
       "      <td>-0.018751</td>\n",
       "      <td>102.451715</td>\n",
       "      <td>235.358377</td>\n",
       "      <td>-0.005369</td>\n",
       "      <td>101.192093</td>\n",
       "      <td>246.964531</td>\n",
       "      <td>0.010406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>104.462366</td>\n",
       "      <td>318.228121</td>\n",
       "      <td>-5.272424e-07</td>\n",
       "      <td>147.859087</td>\n",
       "      <td>298.004780</td>\n",
       "      <td>-0.027812</td>\n",
       "      <td>181.450329</td>\n",
       "      <td>252.615280</td>\n",
       "      <td>-0.031805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>93.628788</td>\n",
       "      <td>212.799540</td>\n",
       "      <td>-0.017536</td>\n",
       "      <td>97.957821</td>\n",
       "      <td>240.048265</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>96.663094</td>\n",
       "      <td>249.643621</td>\n",
       "      <td>0.010595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>131.711702</td>\n",
       "      <td>412.307510</td>\n",
       "      <td>-3.483320e-07</td>\n",
       "      <td>168.481026</td>\n",
       "      <td>401.964226</td>\n",
       "      <td>-0.024451</td>\n",
       "      <td>194.551659</td>\n",
       "      <td>359.942465</td>\n",
       "      <td>-0.027974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007227</td>\n",
       "      <td>116.672125</td>\n",
       "      <td>337.602968</td>\n",
       "      <td>-0.023909</td>\n",
       "      <td>122.332363</td>\n",
       "      <td>359.621401</td>\n",
       "      <td>-0.017577</td>\n",
       "      <td>121.501093</td>\n",
       "      <td>365.053110</td>\n",
       "      <td>-0.008317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>134.165373</td>\n",
       "      <td>410.900230</td>\n",
       "      <td>-3.638212e-07</td>\n",
       "      <td>171.137619</td>\n",
       "      <td>403.897762</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>198.148975</td>\n",
       "      <td>361.638794</td>\n",
       "      <td>-0.029983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007227</td>\n",
       "      <td>121.057186</td>\n",
       "      <td>338.430319</td>\n",
       "      <td>-0.024206</td>\n",
       "      <td>126.223297</td>\n",
       "      <td>360.631142</td>\n",
       "      <td>-0.018549</td>\n",
       "      <td>124.609032</td>\n",
       "      <td>366.415186</td>\n",
       "      <td>-0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>5</td>\n",
       "      <td>211.665516</td>\n",
       "      <td>318.643942</td>\n",
       "      <td>-3.478521e-07</td>\n",
       "      <td>237.260704</td>\n",
       "      <td>312.855806</td>\n",
       "      <td>-0.021787</td>\n",
       "      <td>261.655102</td>\n",
       "      <td>300.156813</td>\n",
       "      <td>-0.032885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015840</td>\n",
       "      <td>188.870659</td>\n",
       "      <td>252.664919</td>\n",
       "      <td>-0.025466</td>\n",
       "      <td>182.116089</td>\n",
       "      <td>240.407038</td>\n",
       "      <td>-0.026138</td>\n",
       "      <td>177.263374</td>\n",
       "      <td>228.607378</td>\n",
       "      <td>-0.023531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>5</td>\n",
       "      <td>212.169533</td>\n",
       "      <td>318.432026</td>\n",
       "      <td>-3.606120e-07</td>\n",
       "      <td>237.857857</td>\n",
       "      <td>312.789459</td>\n",
       "      <td>-0.022022</td>\n",
       "      <td>262.042198</td>\n",
       "      <td>299.791203</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016900</td>\n",
       "      <td>188.836765</td>\n",
       "      <td>252.620001</td>\n",
       "      <td>-0.027613</td>\n",
       "      <td>182.190228</td>\n",
       "      <td>240.143623</td>\n",
       "      <td>-0.028949</td>\n",
       "      <td>177.108479</td>\n",
       "      <td>227.796650</td>\n",
       "      <td>-0.026786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>5</td>\n",
       "      <td>212.201557</td>\n",
       "      <td>318.900661</td>\n",
       "      <td>-3.305985e-07</td>\n",
       "      <td>237.838631</td>\n",
       "      <td>312.825079</td>\n",
       "      <td>-0.022543</td>\n",
       "      <td>261.752777</td>\n",
       "      <td>299.788485</td>\n",
       "      <td>-0.034097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017387</td>\n",
       "      <td>189.020767</td>\n",
       "      <td>252.396469</td>\n",
       "      <td>-0.028404</td>\n",
       "      <td>182.308922</td>\n",
       "      <td>240.092869</td>\n",
       "      <td>-0.029493</td>\n",
       "      <td>177.224693</td>\n",
       "      <td>227.594919</td>\n",
       "      <td>-0.027074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>5</td>\n",
       "      <td>212.403927</td>\n",
       "      <td>318.898802</td>\n",
       "      <td>-3.399586e-07</td>\n",
       "      <td>237.947063</td>\n",
       "      <td>312.354841</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>262.068501</td>\n",
       "      <td>299.327860</td>\n",
       "      <td>-0.033708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017171</td>\n",
       "      <td>189.063187</td>\n",
       "      <td>251.963425</td>\n",
       "      <td>-0.027344</td>\n",
       "      <td>182.217598</td>\n",
       "      <td>239.406652</td>\n",
       "      <td>-0.028341</td>\n",
       "      <td>177.025433</td>\n",
       "      <td>227.192116</td>\n",
       "      <td>-0.026079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>5</td>\n",
       "      <td>212.496223</td>\n",
       "      <td>317.729502</td>\n",
       "      <td>-3.296040e-07</td>\n",
       "      <td>238.431377</td>\n",
       "      <td>312.296076</td>\n",
       "      <td>-0.023082</td>\n",
       "      <td>262.774734</td>\n",
       "      <td>299.338045</td>\n",
       "      <td>-0.034575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017374</td>\n",
       "      <td>188.905144</td>\n",
       "      <td>251.225309</td>\n",
       "      <td>-0.028690</td>\n",
       "      <td>182.328033</td>\n",
       "      <td>238.452973</td>\n",
       "      <td>-0.030126</td>\n",
       "      <td>177.198086</td>\n",
       "      <td>225.577240</td>\n",
       "      <td>-0.028000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label      wristX      wristY        wristZ  thumb_CmcX  thumb_CmcY  \\\n",
       "0         0  109.088745  314.879980 -5.032854e-07  151.700001  293.516436   \n",
       "1         0  109.720602  314.435120 -5.082854e-07  152.480783  292.276154   \n",
       "2         0  104.462366  318.228121 -5.272424e-07  147.859087  298.004780   \n",
       "3         0  131.711702  412.307510 -3.483320e-07  168.481026  401.964226   \n",
       "4         0  134.165373  410.900230 -3.638212e-07  171.137619  403.897762   \n",
       "...     ...         ...         ...           ...         ...         ...   \n",
       "3595      5  211.665516  318.643942 -3.478521e-07  237.260704  312.855806   \n",
       "3596      5  212.169533  318.432026 -3.606120e-07  237.857857  312.789459   \n",
       "3597      5  212.201557  318.900661 -3.305985e-07  237.838631  312.825079   \n",
       "3598      5  212.403927  318.898802 -3.399586e-07  237.947063  312.354841   \n",
       "3599      5  212.496223  317.729502 -3.296040e-07  238.431377  312.296076   \n",
       "\n",
       "      thumb_CmcZ  thumb_McpX  thumb_McpY  thumb_McpZ  ...  pinky_McpZ  \\\n",
       "0      -0.025845  184.029713  249.228258   -0.030217  ...   -0.000314   \n",
       "1      -0.025500  183.990440  248.887711   -0.030684  ...   -0.001665   \n",
       "2      -0.027812  181.450329  252.615280   -0.031805  ...    0.000159   \n",
       "3      -0.024451  194.551659  359.942465   -0.027974  ...   -0.007227   \n",
       "4      -0.026155  198.148975  361.638794   -0.029983  ...   -0.007227   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "3595   -0.021787  261.655102  300.156813   -0.032885  ...   -0.015840   \n",
       "3596   -0.022022  262.042198  299.791203   -0.033089  ...   -0.016900   \n",
       "3597   -0.022543  261.752777  299.788485   -0.034097  ...   -0.017387   \n",
       "3598   -0.022142  262.068501  299.327860   -0.033708  ...   -0.017171   \n",
       "3599   -0.023082  262.774734  299.338045   -0.034575  ...   -0.017374   \n",
       "\n",
       "      pinky_PipX  pinky_PipY  pinky_PipZ  pinky_DipX  pinky_DipY  pinky_DipZ  \\\n",
       "0      97.632666  209.177756   -0.016920  101.957064  235.674677   -0.003543   \n",
       "1      97.538586  209.035378   -0.018751  102.451715  235.358377   -0.005369   \n",
       "2      93.628788  212.799540   -0.017536   97.957821  240.048265   -0.004697   \n",
       "3     116.672125  337.602968   -0.023909  122.332363  359.621401   -0.017577   \n",
       "4     121.057186  338.430319   -0.024206  126.223297  360.631142   -0.018549   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3595  188.870659  252.664919   -0.025466  182.116089  240.407038   -0.026138   \n",
       "3596  188.836765  252.620001   -0.027613  182.190228  240.143623   -0.028949   \n",
       "3597  189.020767  252.396469   -0.028404  182.308922  240.092869   -0.029493   \n",
       "3598  189.063187  251.963425   -0.027344  182.217598  239.406652   -0.028341   \n",
       "3599  188.905144  251.225309   -0.028690  182.328033  238.452973   -0.030126   \n",
       "\n",
       "      pinky_TipX  pinky_TipY  pinky_TipZ  \n",
       "0      99.713421  245.986433    0.011983  \n",
       "1     101.192093  246.964531    0.010406  \n",
       "2      96.663094  249.643621    0.010595  \n",
       "3     121.501093  365.053110   -0.008317  \n",
       "4     124.609032  366.415186   -0.009900  \n",
       "...          ...         ...         ...  \n",
       "3595  177.263374  228.607378   -0.023531  \n",
       "3596  177.108479  227.796650   -0.026786  \n",
       "3597  177.224693  227.594919   -0.027074  \n",
       "3598  177.025433  227.192116   -0.026079  \n",
       "3599  177.198086  225.577240   -0.028000  \n",
       "\n",
       "[3600 rows x 64 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600 entries, 0 to 3599\n",
      "Data columns (total 64 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Label        3600 non-null   int64  \n",
      " 1   wristX       3600 non-null   float64\n",
      " 2   wristY       3600 non-null   float64\n",
      " 3   wristZ       3600 non-null   float64\n",
      " 4   thumb_CmcX   3600 non-null   float64\n",
      " 5   thumb_CmcY   3600 non-null   float64\n",
      " 6   thumb_CmcZ   3600 non-null   float64\n",
      " 7   thumb_McpX   3600 non-null   float64\n",
      " 8   thumb_McpY   3600 non-null   float64\n",
      " 9   thumb_McpZ   3600 non-null   float64\n",
      " 10  thumb_IpX    3600 non-null   float64\n",
      " 11  thumb_IpY    3600 non-null   float64\n",
      " 12  thumb_IpZ    3600 non-null   float64\n",
      " 13  thumb_TipX   3600 non-null   float64\n",
      " 14  thumb_TipY   3600 non-null   float64\n",
      " 15  thumb_TipZ   3600 non-null   float64\n",
      " 16  index_McpX   3600 non-null   float64\n",
      " 17  index_McpY   3600 non-null   float64\n",
      " 18  index_McpZ   3600 non-null   float64\n",
      " 19  index_PipX   3600 non-null   float64\n",
      " 20  index_PipY   3600 non-null   float64\n",
      " 21  index_PipZ   3600 non-null   float64\n",
      " 22  index_DipX   3600 non-null   float64\n",
      " 23  index_DipY   3600 non-null   float64\n",
      " 24  index_Dz     3600 non-null   float64\n",
      " 25  index_TipX   3600 non-null   float64\n",
      " 26  index_TipY   3600 non-null   float64\n",
      " 27  index_TipZ   3600 non-null   float64\n",
      " 28  middle_McpX  3600 non-null   float64\n",
      " 29  middle_McpY  3600 non-null   float64\n",
      " 30  middle_McpZ  3600 non-null   float64\n",
      " 31  middle_PipX  3600 non-null   float64\n",
      " 32  middle_PipY  3600 non-null   float64\n",
      " 33  middle_PipZ  3600 non-null   float64\n",
      " 34  middle_DipX  3600 non-null   float64\n",
      " 35  middle_DipY  3600 non-null   float64\n",
      " 36  middle_DipZ  3600 non-null   float64\n",
      " 37  middle_TipX  3600 non-null   float64\n",
      " 38  middle_TipY  3600 non-null   float64\n",
      " 39  middle_TipZ  3600 non-null   float64\n",
      " 40  ring_McpX    3600 non-null   float64\n",
      " 41  ring_McpY    3600 non-null   float64\n",
      " 42  ring_McpZ    3600 non-null   float64\n",
      " 43  ring_PipX    3600 non-null   float64\n",
      " 44  ring_PipY    3600 non-null   float64\n",
      " 45  ring_PipZ    3600 non-null   float64\n",
      " 46  ring_DipX    3600 non-null   float64\n",
      " 47  ring_DipY    3600 non-null   float64\n",
      " 48  ring_DipZ    3600 non-null   float64\n",
      " 49  ring_TipX    3600 non-null   float64\n",
      " 50  ring_TipY    3600 non-null   float64\n",
      " 51  ring_TipZ    3600 non-null   float64\n",
      " 52  pinky_McpX   3600 non-null   float64\n",
      " 53  pinky_McpY   3600 non-null   float64\n",
      " 54  pinky_McpZ   3600 non-null   float64\n",
      " 55  pinky_PipX   3600 non-null   float64\n",
      " 56  pinky_PipY   3600 non-null   float64\n",
      " 57  pinky_PipZ   3600 non-null   float64\n",
      " 58  pinky_DipX   3600 non-null   float64\n",
      " 59  pinky_DipY   3600 non-null   float64\n",
      " 60  pinky_DipZ   3600 non-null   float64\n",
      " 61  pinky_TipX   3600 non-null   float64\n",
      " 62  pinky_TipY   3600 non-null   float64\n",
      " 63  pinky_TipZ   3600 non-null   float64\n",
      "dtypes: float64(63), int64(1)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype=np.float32, skiprows=1, usecols=range(1, 64)) # Pick the coordinates\n",
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype=np.int32, skiprows=1,usecols=(0)) # Pick the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 63) (3600,)\n"
     ]
    }
   ],
   "source": [
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train and X_test to have an additional feature dimension (e.g., each timestep has 1 feature)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # (num_samples, timesteps, 1 feature)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))  # (num_samples, timesteps, 1 feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Model Bulding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Input((63, )),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(20, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(10, activation='relu'),\n",
    "#     tf.keras.layers.Dense(6, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=X_train.shape[1:3]),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,078</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m5,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_16 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m10,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m20,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_17 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_36 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_18 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m164,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_19 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m3,078\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,166</span> (4.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,048,166\u001b[0m (4.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,166</span> (4.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,048,166\u001b[0m (4.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.2109 - loss: 2.4398 - val_accuracy: 0.3278 - val_loss: 1.6101\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4026 - loss: 1.4198 - val_accuracy: 0.5822 - val_loss: 0.7624\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6920 - loss: 0.6581 - val_accuracy: 0.9122 - val_loss: 0.2611\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9206 - loss: 0.2348 - val_accuracy: 0.9811 - val_loss: 0.0522\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9839 - loss: 0.0484 - val_accuracy: 0.9967 - val_loss: 0.0245\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9859 - loss: 0.0413 - val_accuracy: 0.9967 - val_loss: 0.0187\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9917 - loss: 0.0284 - val_accuracy: 0.9956 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9695 - loss: 0.1108 - val_accuracy: 0.8689 - val_loss: 0.2405\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9190 - loss: 0.2057 - val_accuracy: 0.9989 - val_loss: 0.0116\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9933 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0089 - val_accuracy: 0.9956 - val_loss: 0.0116\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9989 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9999 - loss: 9.3934e-04 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9992 - loss: 0.0017 - val_accuracy: 0.9978 - val_loss: 0.0091\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9384 - loss: 0.2384 - val_accuracy: 0.9956 - val_loss: 0.0312\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9875 - loss: 0.0474 - val_accuracy: 0.9800 - val_loss: 0.0465\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9893 - loss: 0.0301 - val_accuracy: 0.9967 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9645 - loss: 0.1485 - val_accuracy: 0.9967 - val_loss: 0.0144\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9931 - loss: 0.0252 - val_accuracy: 0.9989 - val_loss: 0.0034\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9977 - loss: 0.0060 - val_accuracy: 0.9989 - val_loss: 0.0047\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9978 - val_loss: 0.0050\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9978 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9990 - loss: 0.0018 - val_accuracy: 0.9989 - val_loss: 0.0021\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9996 - loss: 7.4304e-04 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9999 - loss: 6.4829e-04 - val_accuracy: 0.9989 - val_loss: 0.0026\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9989 - loss: 0.0012 - val_accuracy: 0.9978 - val_loss: 0.0022\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9990 - loss: 0.0011 - val_accuracy: 0.9978 - val_loss: 0.0030\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 5.4405e-04 - val_accuracy: 0.9978 - val_loss: 0.0019\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9978 - val_loss: 0.0024\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9989 - val_loss: 0.0040\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 9.7311e-04 - val_accuracy: 0.9989 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9996 - loss: 7.8322e-04 - val_accuracy: 0.9978 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9987 - loss: 0.0011 - val_accuracy: 0.9978 - val_loss: 0.0025\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5426e-04 - val_accuracy: 0.9978 - val_loss: 0.0024\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9998 - loss: 5.5103e-04 - val_accuracy: 0.9978 - val_loss: 0.0032\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9998 - loss: 2.1951e-04 - val_accuracy: 0.9978 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9988 - loss: 0.0011 - val_accuracy: 0.9978 - val_loss: 0.0021\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9999 - loss: 3.3391e-04 - val_accuracy: 0.9978 - val_loss: 0.0022\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 4.6080e-04 - val_accuracy: 0.9989 - val_loss: 0.0022\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 0.0012 - val_accuracy: 0.9989 - val_loss: 0.0024\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9997 - loss: 3.6917e-04 - val_accuracy: 0.9989 - val_loss: 0.0023\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.2161e-04 - val_accuracy: 0.9989 - val_loss: 0.0021\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9998 - loss: 2.4613e-04 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9992 - loss: 6.0860e-04 - val_accuracy: 0.9978 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9993 - loss: 6.3723e-04 - val_accuracy: 0.9978 - val_loss: 0.0017\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 2.5660e-04 - val_accuracy: 0.9978 - val_loss: 0.0016\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 1.9407e-04 - val_accuracy: 0.9989 - val_loss: 0.0018\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 4.7265e-04 - val_accuracy: 0.9989 - val_loss: 0.0018\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 3.9899e-04 - val_accuracy: 0.9989 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9995 - loss: 4.1208e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 9.8046e-05 - val_accuracy: 0.9989 - val_loss: 0.0015\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.2622e-04 - val_accuracy: 0.9989 - val_loss: 0.0016\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0339e-04 - val_accuracy: 0.9989 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9987 - loss: 0.0011 - val_accuracy: 0.9989 - val_loss: 0.0022\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9998 - loss: 4.5956e-04 - val_accuracy: 0.9989 - val_loss: 0.0019\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.2995e-04 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 6.1667e-04 - val_accuracy: 0.9978 - val_loss: 0.0021\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9988 - loss: 0.0012 - val_accuracy: 0.9978 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9998 - loss: 1.8438e-04 - val_accuracy: 0.9978 - val_loss: 0.0023\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9993 - loss: 4.8624e-04 - val_accuracy: 0.9978 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9996 - loss: 7.2667e-04 - val_accuracy: 0.9978 - val_loss: 0.0017\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9984 - loss: 0.0014 - val_accuracy: 0.9989 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 3.1215e-04 - val_accuracy: 0.9989 - val_loss: 0.0031\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.3295e-04 - val_accuracy: 0.9978 - val_loss: 0.0023\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9996 - loss: 7.9962e-04 - val_accuracy: 0.9978 - val_loss: 0.0026\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 6.8843e-04 - val_accuracy: 0.9978 - val_loss: 0.0027\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.7720e-04 - val_accuracy: 0.9978 - val_loss: 0.0027\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9996 - loss: 3.7043e-04 - val_accuracy: 0.9978 - val_loss: 0.0025\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9997 - loss: 6.0367e-04 - val_accuracy: 0.9978 - val_loss: 0.0027\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9994 - loss: 5.8179e-04 - val_accuracy: 0.9989 - val_loss: 0.0025\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 4.2798e-04 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9999 - loss: 7.2065e-04 - val_accuracy: 0.9978 - val_loss: 0.0019\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.3196e-04 - val_accuracy: 0.9978 - val_loss: 0.0020\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9999 - loss: 4.3275e-04 - val_accuracy: 0.9978 - val_loss: 0.0021\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9991 - loss: 7.3853e-04 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9997 - loss: 2.7704e-04 - val_accuracy: 0.9989 - val_loss: 0.0021\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9998 - loss: 6.6758e-04 - val_accuracy: 0.9989 - val_loss: 0.0020\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9981 - loss: 0.0016 - val_accuracy: 0.9978 - val_loss: 0.0021\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9994 - loss: 5.4475e-04 - val_accuracy: 0.9989 - val_loss: 0.0015\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9998 - loss: 3.9868e-04 - val_accuracy: 0.9989 - val_loss: 0.0018\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9998 - loss: 6.9351e-04 - val_accuracy: 0.9989 - val_loss: 0.0016\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9992 - loss: 9.7414e-04 - val_accuracy: 0.9989 - val_loss: 0.0015\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 6.2280e-04 - val_accuracy: 0.9978 - val_loss: 0.0020\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9992 - loss: 6.8310e-04 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9998 - loss: 3.8058e-04 - val_accuracy: 0.9989 - val_loss: 0.0012\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9997 - loss: 2.4995e-04 - val_accuracy: 0.9989 - val_loss: 0.0015\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9998 - loss: 7.2146e-04 - val_accuracy: 0.9978 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9999 - loss: 1.9574e-04 - val_accuracy: 0.9989 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9988 - loss: 9.7613e-04 - val_accuracy: 0.9989 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9996 - loss: 3.5879e-04 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9999 - loss: 2.9205e-04 - val_accuracy: 0.9989 - val_loss: 0.0014\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.0525e-04 - val_accuracy: 0.9989 - val_loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18488a1e530>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    #callbacks=[cp_callback, es_callback],\n",
    "    callbacks=[History()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Accuracy: 0.9989\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       172\n",
      "           1       0.99      1.00      1.00       153\n",
      "           2       1.00      0.99      1.00       150\n",
      "           3       1.00      1.00      1.00       145\n",
      "           4       1.00      1.00      1.00       144\n",
      "           5       1.00      1.00      1.00       136\n",
      "\n",
      "    accuracy                           1.00       900\n",
      "   macro avg       1.00      1.00      1.00       900\n",
      "weighted avg       1.00      1.00      1.00       900\n",
      "\n",
      "Confusion Matrix:\n",
      "[[172   0   0   0   0   0]\n",
      " [  0 153   0   0   0   0]\n",
      " [  0   1 149   0   0   0]\n",
      " [  0   0   0 145   0   0]\n",
      " [  0   0   0   0 144   0]\n",
      " [  0   0   0   0   0 136]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)  # Get predicted probabilities for each class\n",
    "\n",
    "# Step 2: Convert predicted probabilities to predicted class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Choose the class with the highest probability\n",
    "\n",
    "# Step 3: Evaluate predictions\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report (precision, recall, F1-score, etc.)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
